{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные моделиё\n",
    "from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки:\n",
    "* age - возраст\n",
    "* workclass - статус занятости\n",
    "* fnlwgt - общий вес, это число людей, которых, по мнению эксперта, представляет эта категория занятости\n",
    "* education - образование\n",
    "* education.num - образовательная ступень (в виде числа)\n",
    "* marital.status - брачный статус\n",
    "* occupation - профессия\n",
    "* relationship - тип отношений\n",
    "* race - раса\n",
    "* sex - пол\n",
    "* capital.gain - ежегодный дополнительный прирост капитала\n",
    "* capital.loss - ежегодная дополнительная потеря капитала\n",
    "* hours.per.week - число рабочих часов в неделю\n",
    "* native.country - Родина \n",
    "* income - категория дохода (целевой признак)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital.status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native.country']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['income'] = data['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "types = data.dtypes\n",
    "cat_features = list(types[(types == 'object')].index)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data = data.copy()\n",
    "#Определяем школьников в отдельную категорию\n",
    "adult_data['education'] = adult_data['education'].apply(\n",
    "    lambda x: 'School' if x == '11th' or x == '7th-8th' or x == '10th' \n",
    "        or x == '5th-6th' or x == '9th' or x == '12th' or x == '1st-4th' else x\n",
    ")\n",
    "#Объединяем категории Assoc-acdm и Assoc-voc (доценты)\n",
    "adult_data['education'] = adult_data['education'].apply(\n",
    "    lambda x: 'Associate' if x == 'Assoc-acdm' or x == 'Assoc-voc' else x\n",
    ")\n",
    "#Объединяем вдовцов,разведенных и живущих раздельно в одну категорию\n",
    "adult_data['marital.status'] = adult_data['marital.status'].apply(\n",
    "    lambda x: 'Prev-Married' if (x == 'Widowed' or x == 'Divorced' or x == 'Separated') else x\n",
    ")\n",
    "#Объединяем всех женатых/за мужем в одну категорию\n",
    "adult_data['marital.status'] = adult_data['marital.status'].apply(\n",
    "    lambda x: 'Married' if (x == 'Married-civ-spouse' or x == 'Married-spouse-absent' or x == 'Married-AF-spouse') else x\n",
    ")\n",
    "#Объединяем мужей и жен в одну категорию, остальных в другую\n",
    "adult_data['relationship'] = adult_data['relationship'].apply(\n",
    "    lambda x: 'In relationship' if (x == 'Husband' or x == 'Whife') else 'Not in relationship'\n",
    ")\n",
    "\n",
    "#Объединяем типы занятоностей, не приносящих дохода в одну категорию\n",
    "adult_data['workclass'] = adult_data['workclass'].apply(\n",
    "    lambda x: 'No income' if x == 'Never-worked' or x == 'Without-pay' else x\n",
    ")\n",
    "#Объединяем всех приезжих в одну категорию\n",
    "adult_data['native.country'] = adult_data['native.country'].apply(\n",
    "    lambda x: 'Other' if x != 'United-States' else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income</th>\n",
       "      <th>capital_diff</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_No income</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_Sales</th>\n",
       "      <th>occupation_Tech-support</th>\n",
       "      <th>occupation_Transport-moving</th>\n",
       "      <th>relationship_Not in relationship</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>native.country_United-States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>11.252262</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8.379539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>11.797134</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8.379539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>12.133835</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8.379539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>11.851966</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8.268988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>12.486216</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8.268988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     fnlwgt  hours.per.week  income  capital_diff  \\\n",
       "0   90  11.252262              40       0      8.379539   \n",
       "1   82  11.797134              18       0      8.379539   \n",
       "2   66  12.133835              40       0      8.379539   \n",
       "3   54  11.851966              40       0      8.268988   \n",
       "4   41  12.486216              40       0      8.268988   \n",
       "\n",
       "   workclass_Federal-gov  workclass_Local-gov  workclass_No income  \\\n",
       "0                      0                    0                    0   \n",
       "1                      0                    0                    0   \n",
       "2                      0                    0                    0   \n",
       "3                      0                    0                    0   \n",
       "4                      0                    0                    0   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-inc  ...  occupation_Sales  \\\n",
       "0                  0                       0  ...                 0   \n",
       "1                  1                       0  ...                 0   \n",
       "2                  0                       0  ...                 0   \n",
       "3                  1                       0  ...                 0   \n",
       "4                  1                       0  ...                 0   \n",
       "\n",
       "   occupation_Tech-support  occupation_Transport-moving  \\\n",
       "0                        0                            0   \n",
       "1                        0                            0   \n",
       "2                        0                            0   \n",
       "3                        0                            0   \n",
       "4                        0                            0   \n",
       "\n",
       "   relationship_Not in relationship  race_Asian-Pac-Islander  race_Black  \\\n",
       "0                                 1                        0           0   \n",
       "1                                 1                        0           0   \n",
       "2                                 1                        0           1   \n",
       "3                                 1                        0           0   \n",
       "4                                 1                        0           0   \n",
       "\n",
       "   race_Other  race_White  sex_Male  native.country_United-States  \n",
       "0           0           1         0                             1  \n",
       "1           0           1         0                             1  \n",
       "2           0           0         0                             1  \n",
       "3           0           1         0                             1  \n",
       "4           0           1         0                             1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Логарифмируем числовые признаки, чтобы придать им форму нормального распределения\n",
    "adult_data['capital.gain'] = np.log(adult_data['capital.gain']+1)\n",
    "adult_data['capital.loss'] = np.log(adult_data['capital.loss']+1)\n",
    "adult_data['fnlwgt'] = np.log(adult_data['fnlwgt']+1)\n",
    "\n",
    "#Создаем новый признак - разность между приростом капитала и его убылью\n",
    "adult_data['capital_diff'] = abs((adult_data['capital.gain'] - adult_data['capital.loss']))\n",
    "\n",
    "#Удаляем лишние признаки\n",
    "adult_data = adult_data.drop(['education.num', 'capital.gain', 'capital.loss'], axis=1)\n",
    "\n",
    "dummies_data = pd.get_dummies(adult_data, drop_first=True)\n",
    "dummies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummies_data.drop(['income'], axis=1)\n",
    "y = dummies_data['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 1, test_size = 0.2)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Hyperopt : 0.2.7\n"
     ]
    }
   ],
   "source": [
    "#делаем импорт и выведем версию библиотеки\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "# fmin - основная функция, она будет минимизировать наш функционал\n",
    "# tpe - алгоритм оптимизации\n",
    "# hp - включает набор методов для объявления пространства поиска гиперпараметров\n",
    "# trails - используется для логирования результатов\n",
    "\n",
    "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.5\n",
    "\n",
    "Реализуйте настройку гиперпараметров алгоритма RandomForestClassifier(random_state=42) со следующей сеткой значений:\n",
    "\n",
    "n_estimators = от 100 до 300 включительно с шагом 10\n",
    "min_samples_leaf = от 3 до 7 с шагом 1\n",
    "max_depth = от 15 до 40 с шагом 1\n",
    "Используйте Hyperopt с параметрами max_evals = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={'n_estimators': hp.quniform('n_estimators', 100, 300, 10),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 40, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 3, 7, 1)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train_scaled, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:28<00:00,  4.40s/trial, best loss: -0.7639828998931244]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 30.0, 'min_samples_leaf': 3.0, 'n_estimators': 130.0}\n"
     ]
    }
   ],
   "source": [
    "# %%time # начинаем подбор гиперпараметров\n",
    "\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space = space, # пространство гиперпараметров\n",
    "          algo = tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals = 20, # максимальное количество итераций\n",
    "          trials = trials, # логирование результатов\n",
    "          # rstate=np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
    "          rstate = np.random.default_rng(random_state)\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.68\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(random_state=random_state, n_estimators=int(best['n_estimators']),   max_depth=int(best['max_depth']),min_samples_leaf=int(best['min_samples_leaf']))\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # зададим пространство поиска гиперпараметров\n",
    "# space={'n_estimators': hp.quniform('n_estimators', 100, 300, 10),\n",
    "#        'max_depth' : hp.quniform('max_depth', 15, 40, 1),\n",
    "#        'min_samples_leaf': hp.quniform('min_samples_leaf', 3, 7, 1)\n",
    "#       }\n",
    "# # зафксируем random_state\n",
    "# random_state = 42\n",
    "# def hyperopt_gb(params, cv=5, X=X_train_scaled, y=y_train, random_state=random_state):\n",
    "#     # функция получает комбинацию гиперпараметров в \"params\"\n",
    "#     params = {'n_estimators': int(params['n_estimators']), \n",
    "#               'max_depth': int(params['max_depth']), \n",
    "#               'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "#               }\n",
    "#     # используем эту комбинацию для построения модели\n",
    "#     model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "#  \n",
    "#     # обучаем модель\n",
    "#     model.fit(X, y)\n",
    "#     score = metrics.f1_score(y, model.predict(X))\n",
    "#     # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "#     return -score\n",
    "#  \n",
    "#     # начинаем подбор гиперпараметров\n",
    "# best=fmin(hyperopt_gb, # наша функция \n",
    "#           space=space, # пространство гиперпараметров\n",
    "#           algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "#           max_evals=20, # максимальное количество итераций\n",
    "#           trials=trials, # логирование результатов\n",
    "#           # rstate=np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
    "#           rstate = np.random.default_rng(random_state)\n",
    "#          )\n",
    "#  \n",
    "# # рассчитаем точность для тестовой выборки\n",
    "# model = ensemble.RandomForestClassifier(random_state=random_state, n_estimators=int(best['n_estimators']),   max_depth=int(best['max_depth']),min_samples_leaf=int(best['min_samples_leaf']))\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "# y_test_pred = model.predict(X_test_scaled)\n",
    "# print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.10\n",
    "\n",
    "Реализуйте настройку гиперпараметров алгоритма RandomForestClassifier(random_state=42) со следующей сеткой значений:\n",
    "\n",
    "n_estimators = от 100 до 300 включительно с шагом 10\n",
    "min_samples_leaf = от 3 до 7 с шагом 1\n",
    "max_depth = от 15 до 40 с шагом 1\n",
    "Используйте Optuna с параметрами n_trails = 20.\n",
    "\n",
    "В ответе укажите метрику f1 на тестовой выборке, значение округлите до двух знаков после запятой (например, 0.58)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Optuna: 3.0.2\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "print(\"Версия Optuna: {}\".format(optuna.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  n_estimators = trial.suggest_int('n_estimators', 100, 300, 10)\n",
    "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 3, 7, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  score = metrics.f1_score(y_train, model.predict(X_train_scaled))\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-05 22:45:56,965]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:00,033]\u001b[0m Trial 0 finished with value: 0.711710071025314 and parameters: {'n_estimators': 130, 'max_depth': 30, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.711710071025314.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:04,899]\u001b[0m Trial 1 finished with value: 0.7041225829989054 and parameters: {'n_estimators': 210, 'max_depth': 37, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.711710071025314.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:09,089]\u001b[0m Trial 2 finished with value: 0.7020730141258484 and parameters: {'n_estimators': 190, 'max_depth': 20, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.711710071025314.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:14,256]\u001b[0m Trial 3 finished with value: 0.7387516838796586 and parameters: {'n_estimators': 210, 'max_depth': 32, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.7387516838796586.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:19,461]\u001b[0m Trial 4 finished with value: 0.7087816091954022 and parameters: {'n_estimators': 230, 'max_depth': 17, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.7387516838796586.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:21,672]\u001b[0m Trial 5 finished with value: 0.6921652157807001 and parameters: {'n_estimators': 100, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.7387516838796586.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:25,653]\u001b[0m Trial 6 finished with value: 0.7399713467048711 and parameters: {'n_estimators': 160, 'max_depth': 36, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.7399713467048711.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:32,423]\u001b[0m Trial 7 finished with value: 0.7286807580174927 and parameters: {'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.7399713467048711.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:39,302]\u001b[0m Trial 8 finished with value: 0.7588734912829682 and parameters: {'n_estimators': 270, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:42,518]\u001b[0m Trial 9 finished with value: 0.7401165396683101 and parameters: {'n_estimators': 130, 'max_depth': 32, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:49,610]\u001b[0m Trial 10 finished with value: 0.7532841461220083 and parameters: {'n_estimators': 280, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:46:56,849]\u001b[0m Trial 11 finished with value: 0.7541809027153389 and parameters: {'n_estimators': 290, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:03,350]\u001b[0m Trial 12 finished with value: 0.7562483203439934 and parameters: {'n_estimators': 250, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:09,979]\u001b[0m Trial 13 finished with value: 0.756514730903555 and parameters: {'n_estimators': 260, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:16,089]\u001b[0m Trial 14 finished with value: 0.7209154481881754 and parameters: {'n_estimators': 260, 'max_depth': 28, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:22,414]\u001b[0m Trial 15 finished with value: 0.7422419252691577 and parameters: {'n_estimators': 260, 'max_depth': 21, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:28,297]\u001b[0m Trial 16 finished with value: 0.7399030694668821 and parameters: {'n_estimators': 240, 'max_depth': 40, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:34,574]\u001b[0m Trial 17 finished with value: 0.7222373065435788 and parameters: {'n_estimators': 270, 'max_depth': 27, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:39,023]\u001b[0m Trial 18 finished with value: 0.7475256433327334 and parameters: {'n_estimators': 180, 'max_depth': 22, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 22:47:44,178]\u001b[0m Trial 19 finished with value: 0.7012417823228634 and parameters: {'n_estimators': 230, 'max_depth': 28, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.7588734912829682.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 47s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 270, 'max_depth': 27, 'min_samples_leaf': 3}\n",
      "f1_score на обучающем наборе: 0.76\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.86\n",
      "f1_score на тестовом наборе: 0.68\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test_scaled, y_test)))\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
